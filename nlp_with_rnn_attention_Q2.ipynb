{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_zip = tf.keras.utils.get_file('spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip', extract=True)\n",
    "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = w.strip()\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "b'<start> ? \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
     ]
    }
   ],
   "source": [
    "en_sentence = u\"May I borrow this book?\"\n",
    "sp_sentence = u\"?¿Puedo tomar prestado este libro?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path, num_examples):\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "    return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
      "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
     ]
    }
   ],
   "source": [
    "en, sp = create_dataset(path_to_file, None)\n",
    "print(en[-1])\n",
    "print(sp[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenize = keras.preprocessing.text.Tokenizer(filters=\" \")\n",
    "    lang_tokenize.fit_on_texts(lang)\n",
    "    tensor = lang_tokenize.texts_to_sequences(lang)\n",
    "    tensor = keras.preprocessing.sequence.pad_sequences(tensor, padding=\"post\")\n",
    "    return tensor, lang_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_examples = 100000\n",
    "target_tensor, input_tensor, targ_lang, inp_lang = load_dataset(path_to_file, num_examples)\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "target_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t != 0:\n",
    "            print(\"%d =====> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 =====> <start>\n",
      "45 =====> they\n",
      "18 =====> do\n",
      "166 =====> nothing\n",
      "181 =====> but\n",
      "587 =====> cry\n",
      "3 =====> .\n",
      "2 =====> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 =====> <start>\n",
      "7 =====> no\n",
      "1034 =====> hacen\n",
      "34 =====> mas\n",
      "4 =====> que\n",
      "600 =====> llorar\n",
      "3 =====> .\n",
      "2 =====> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = len(input_tensor_train)\n",
    "batch_size = 256\n",
    "steps_per_epoch = len(input_tensor_train) // batch_size\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "vocab_tar_size = len(targ_lang.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(buffer_size)\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([256, 17]), TensorShape([256, 20]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, encoding_units, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.encoding_units = encoding_units\n",
    "        self.embedding = keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = keras.layers.GRU(self.encoding_units, return_sequences=True, return_state=True, recurrent_initializer=\"glorot_uniform\")\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_size, self.encoding_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([256, 17, 1024]), TensorShape([256, 1024]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, batch_size)\n",
    "\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "sample_output.shape, sample_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanuAttention(keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanuAttention, self).__init__()\n",
    "        self.W1 = keras.layers.Dense(units)\n",
    "        self.W2 = keras.layers.Dense(units)\n",
    "        self.V = keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([256, 1024]), TensorShape([256, 17, 1]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_layer = BahdanuAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "attention_result.shape, attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, decoding_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.decoding_units = decoding_units\n",
    "        self.embedding = keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = keras.layers.GRU(self.decoding_units, return_sequences=True, return_state=True, recurrent_initializer=\"glorot_uniform\")\n",
    "        self.fc = keras.layers.Dense(vocab_size)\n",
    "        self.attention = BahdanuAttention(self.decoding_units)\n",
    "\n",
    "    def call(self, x, hidden, encoding_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, encoding_output)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.gru(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([256, 20708])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, batch_size)\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((batch_size, 1)), sample_hidden, sample_output)\n",
    "sample_decoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input, target, encoding_hidden):\n",
    "    loss = 0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        encoding_output, encoding_hidden = encoder(input, encoding_hidden)\n",
    "        decoding_hidden = encoding_hidden\n",
    "        decoding_input = tf.expand_dims([targ_lang.word_index[\"<start>\"]] * batch_size, 1)\n",
    "        \n",
    "        for t in range(1, target.shape[1]):\n",
    "            predictions, decoding_hidden, _ = decoder(decoding_input, decoding_hidden, encoding_output)\n",
    "            loss += loss_function(target[:, t], predictions)\n",
    "            decoding_input = tf.expand_dims(target[:, t], 1)\n",
    "        \n",
    "        batch_loss = (loss / int(target.shape[1]))\n",
    "        variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "        return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1    Batch : 0    Loss : 3.734734296798706\n",
      "Epoch : 1    Batch : 100    Loss : 1.9730770587921143\n",
      "Epoch : 1    Batch : 200    Loss : 1.7939656972885132\n",
      "Epoch : 1    Batch : 300    Loss : 1.7173489332199097\n",
      "Time taken for 1 epoch 161.0663366317749 sec\n",
      "\n",
      "Epoch : 2    Batch : 0    Loss : 1.610432505607605\n",
      "Epoch : 2    Batch : 100    Loss : 1.5219004154205322\n",
      "Epoch : 2    Batch : 200    Loss : 1.480718970298767\n",
      "Epoch : 2    Batch : 300    Loss : 1.3568395376205444\n",
      "Time taken for 1 epoch 147.56732964515686 sec\n",
      "\n",
      "Epoch : 3    Batch : 0    Loss : 1.3056440353393555\n",
      "Epoch : 3    Batch : 100    Loss : 1.3161450624465942\n",
      "Epoch : 3    Batch : 200    Loss : 1.3059170246124268\n",
      "Epoch : 3    Batch : 300    Loss : 1.22095787525177\n",
      "Time taken for 1 epoch 148.4776930809021 sec\n",
      "\n",
      "Epoch : 4    Batch : 0    Loss : 1.2077354192733765\n",
      "Epoch : 4    Batch : 100    Loss : 1.0960744619369507\n",
      "Epoch : 4    Batch : 200    Loss : 1.0786186456680298\n",
      "Epoch : 4    Batch : 300    Loss : 1.082518458366394\n",
      "Time taken for 1 epoch 148.6562042236328 sec\n",
      "\n",
      "Epoch : 5    Batch : 0    Loss : 1.0399702787399292\n",
      "Epoch : 5    Batch : 100    Loss : 0.9407912492752075\n",
      "Epoch : 5    Batch : 200    Loss : 0.9140701293945312\n",
      "Epoch : 5    Batch : 300    Loss : 0.8672065734863281\n",
      "Time taken for 1 epoch 148.32831358909607 sec\n",
      "\n",
      "Epoch : 6    Batch : 0    Loss : 0.7503552436828613\n",
      "Epoch : 6    Batch : 100    Loss : 0.7175015807151794\n",
      "Epoch : 6    Batch : 200    Loss : 0.6969549059867859\n",
      "Epoch : 6    Batch : 300    Loss : 0.6962271332740784\n",
      "Time taken for 1 epoch 148.01168847084045 sec\n",
      "\n",
      "Epoch : 7    Batch : 0    Loss : 0.5574530363082886\n",
      "Epoch : 7    Batch : 100    Loss : 0.5302188992500305\n",
      "Epoch : 7    Batch : 200    Loss : 0.5342327356338501\n",
      "Epoch : 7    Batch : 300    Loss : 0.5038971900939941\n",
      "Time taken for 1 epoch 148.29586338996887 sec\n",
      "\n",
      "Epoch : 8    Batch : 0    Loss : 0.39649006724357605\n",
      "Epoch : 8    Batch : 100    Loss : 0.41966715455055237\n",
      "Epoch : 8    Batch : 200    Loss : 0.41421595215797424\n",
      "Epoch : 8    Batch : 300    Loss : 0.4049399495124817\n",
      "Time taken for 1 epoch 147.9194951057434 sec\n",
      "\n",
      "Epoch : 9    Batch : 0    Loss : 0.31186848878860474\n",
      "Epoch : 9    Batch : 100    Loss : 0.3403241038322449\n",
      "Epoch : 9    Batch : 200    Loss : 0.3465520739555359\n",
      "Epoch : 9    Batch : 300    Loss : 0.3479286730289459\n",
      "Time taken for 1 epoch 148.32092475891113 sec\n",
      "\n",
      "Epoch : 10    Batch : 0    Loss : 0.25740572810173035\n",
      "Epoch : 10    Batch : 100    Loss : 0.29085269570350647\n",
      "Epoch : 10    Batch : 200    Loss : 0.2904212474822998\n",
      "Epoch : 10    Batch : 300    Loss : 0.2778439223766327\n",
      "Time taken for 1 epoch 148.242014169693 sec\n",
      "\n",
      "Epoch : 11    Batch : 0    Loss : 0.22216324508190155\n",
      "Epoch : 11    Batch : 100    Loss : 0.2229720652103424\n",
      "Epoch : 11    Batch : 200    Loss : 0.19765597581863403\n",
      "Epoch : 11    Batch : 300    Loss : 0.2436327487230301\n",
      "Time taken for 1 epoch 143.34623527526855 sec\n",
      "\n",
      "Epoch : 12    Batch : 0    Loss : 0.1724790781736374\n",
      "Epoch : 12    Batch : 100    Loss : 0.18161869049072266\n",
      "Epoch : 12    Batch : 200    Loss : 0.1850232183933258\n",
      "Epoch : 12    Batch : 300    Loss : 0.19099406898021698\n",
      "Time taken for 1 epoch 146.1778175830841 sec\n",
      "\n",
      "Epoch : 13    Batch : 0    Loss : 0.14789216220378876\n",
      "Epoch : 13    Batch : 100    Loss : 0.15493826568126678\n",
      "Epoch : 13    Batch : 200    Loss : 0.13609041273593903\n",
      "Epoch : 13    Batch : 300    Loss : 0.1794923096895218\n",
      "Time taken for 1 epoch 147.34549140930176 sec\n",
      "\n",
      "Epoch : 14    Batch : 0    Loss : 0.12425296753644943\n",
      "Epoch : 14    Batch : 100    Loss : 0.13915704190731049\n",
      "Epoch : 14    Batch : 200    Loss : 0.13355468213558197\n",
      "Epoch : 14    Batch : 300    Loss : 0.13478390872478485\n",
      "Time taken for 1 epoch 146.6357650756836 sec\n",
      "\n",
      "Epoch : 15    Batch : 0    Loss : 0.10682296752929688\n",
      "Epoch : 15    Batch : 100    Loss : 0.11712296307086945\n",
      "Epoch : 15    Batch : 200    Loss : 0.12321677058935165\n",
      "Epoch : 15    Batch : 300    Loss : 0.11101885139942169\n",
      "Time taken for 1 epoch 147.0328404903412 sec\n",
      "\n",
      "Epoch : 16    Batch : 0    Loss : 0.08632713556289673\n",
      "Epoch : 16    Batch : 100    Loss : 0.09404725581407547\n",
      "Epoch : 16    Batch : 200    Loss : 0.11060823500156403\n",
      "Epoch : 16    Batch : 300    Loss : 0.0988183245062828\n",
      "Time taken for 1 epoch 146.36909413337708 sec\n",
      "\n",
      "Epoch : 17    Batch : 0    Loss : 0.07510901987552643\n",
      "Epoch : 17    Batch : 100    Loss : 0.07672462612390518\n",
      "Epoch : 17    Batch : 200    Loss : 0.09307121485471725\n",
      "Epoch : 17    Batch : 300    Loss : 0.08624985069036484\n",
      "Time taken for 1 epoch 146.32594752311707 sec\n",
      "\n",
      "Epoch : 18    Batch : 0    Loss : 0.05728056654334068\n",
      "Epoch : 18    Batch : 100    Loss : 0.07205097377300262\n",
      "Epoch : 18    Batch : 200    Loss : 0.08351891487836838\n",
      "Epoch : 18    Batch : 300    Loss : 0.09529856592416763\n",
      "Time taken for 1 epoch 146.669935464859 sec\n",
      "\n",
      "Epoch : 19    Batch : 0    Loss : 0.058994900435209274\n",
      "Epoch : 19    Batch : 100    Loss : 0.06461457908153534\n",
      "Epoch : 19    Batch : 200    Loss : 0.06863512098789215\n",
      "Epoch : 19    Batch : 300    Loss : 0.08857307583093643\n",
      "Time taken for 1 epoch 146.43715381622314 sec\n",
      "\n",
      "Epoch : 20    Batch : 0    Loss : 0.05197121575474739\n",
      "Epoch : 20    Batch : 100    Loss : 0.06164565309882164\n",
      "Epoch : 20    Batch : 200    Loss : 0.06803549826145172\n",
      "Epoch : 20    Batch : 300    Loss : 0.07854615896940231\n",
      "Time taken for 1 epoch 146.3997447490692 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    encoding_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (input, target)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(input, target, encoding_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f\"Epoch : {epoch+1}    Batch : {batch}    Loss : {batch_loss.numpy()}\")\n",
    "\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    \n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(\" \")]\n",
    "    inputs = keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding=\"post\")\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = \"\"\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    encoding_output, encoding_hidden = encoder(inputs, hidden)\n",
    "    decoding_hidden = encoding_hidden\n",
    "    decoding_input = tf.expand_dims([targ_lang.word_index[\"<start>\"]], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        prediction, decoding_hidden, attention_weights = decoder(decoding_input, decoding_hidden, encoding_output)\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        prediction_id = tf.argmax(prediction[0]).numpy()\n",
    "        result += targ_lang.index_word[prediction_id] + \" \"\n",
    "        \n",
    "        if targ_lang.index_word[prediction_id] == \"<end>\":\n",
    "            return result, sentence, attention_plot\n",
    "        \n",
    "        decoding_input = tf.expand_dims([prediction_id], 0)\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Predicted translation: {}'.format(result))\n",
    "\n",
    "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> it s very cold here <end>\n",
      "Predicted translation: esta muy frio que pela . <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ozing\\miniconda3\\envs\\handson-ml2\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  \n",
      "C:\\Users\\ozing\\miniconda3\\envs\\handson-ml2\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u\"it's very cold here\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4e1c02ba9a4315c9c9b9f3ccdc568bf0028a114bbf7c4447cf8df78c88a2f71"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('handson-ml2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
