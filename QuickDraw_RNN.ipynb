{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = \"http://download.tensorflow.org/data/\"\n",
    "FILENAME = \"quickdraw_tutorial_dataset_v1.tar.gz\"\n",
    "filepath = keras.utils.get_file(FILENAME, DOWNLOAD_ROOT + FILENAME, cache_subdir=\"datasets/quickdraw\", extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quickdraw_dir = Path(filepath).parent\n",
    "train_files = sorted([str(path) for path in quickdraw_dir.glob(\"training.tfrecord-*\")])\n",
    "eval_files = sorted([str(path) for path in quickdraw_dir.glob(\"eval.tfrecord-*\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(quickdraw_dir / \"eval.tfrecord.classes\") as test_classes_file:\n",
    "    test_classes = test_classes_file.readlines()\n",
    "    \n",
    "with open(quickdraw_dir / \"training.tfrecord.classes\") as train_classes_file:\n",
    "    train_classes = train_classes_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_classes == test_classes\n",
    "class_names = [name.strip().lower() for name in train_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(data_batch):\n",
    "    feature_descriptions = {\n",
    "        \"ink\": tf.io.VarLenFeature(dtype=tf.float32),\n",
    "        \"shape\": tf.io.FixedLenFeature([2], dtype=tf.int64),\n",
    "        \"class_index\": tf.io.FixedLenFeature([1], dtype=tf.int64)\n",
    "    }\n",
    "    examples = tf.io.parse_example(data_batch, feature_descriptions)\n",
    "    flat_sketches = tf.sparse.to_dense(examples[\"ink\"])\n",
    "    sketches = tf.reshape(flat_sketches, shape=[tf.size(data_batch), -1, 3])\n",
    "    lengths = examples[\"shape\"][:, 0]\n",
    "    labels = examples[\"class_index\"][:, 0]\n",
    "    return sketches, lengths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quickdraw_dataset(filepaths, batch_size=32, shuffle_buffer_size=None, n_parse_threads=5, n_read_threads=5, cache=False):\n",
    "    dataset = tf.data.TFRecordDataset(filepaths, num_parallel_reads=n_read_threads)\n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(parse, num_parallel_calls=n_parse_threads)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = quickdraw_dataset(train_files, shuffle_buffer_size=10000)\n",
    "valid_set = quickdraw_dataset(eval_files[:5])\n",
    "test_set = quickdraw_dataset(eval_files[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sketches, lengths, labels in train_set.take(1):\n",
    "    print(\"sketches =\", sketches)\n",
    "    print(\"lengths =\", lengths)\n",
    "    print(\"labels =\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_sketch(sketch, label=None):\n",
    "    origin = np.array([[0., 0., 0.]])\n",
    "    sketch = np.r_[origin, sketch]\n",
    "    stroke_end_indices = np.argwhere(sketch[:, -1]==1.)[:, 0]\n",
    "    coordinates = np.cumsum(sketch[:, :2], axis=0)\n",
    "    strokes = np.split(coordinates, stroke_end_indices + 1)\n",
    "    title = class_names[label.numpy()] if label is not None else \"Try to guess\"\n",
    "    plt.title(title)\n",
    "    plt.plot(coordinates[:, 0], -coordinates[:, 1], \"y:\")\n",
    "    for stroke in strokes:\n",
    "        plt.plot(stroke[:, 0], -stroke[:, 1], \".-\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def draw_sketches(sketches, lengths, labels):\n",
    "    n_sketches = len(sketches)\n",
    "    n_cols = 4\n",
    "    n_rows = (n_sketches - 1) // n_cols + 1\n",
    "    plt.figure(figsize=(n_cols * 3, n_rows * 3.5))\n",
    "    for index, sketch, length, label in zip(range(n_sketches), sketches, lengths, labels):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        draw_sketch(sketch[:length], label)\n",
    "    plt.show()\n",
    "\n",
    "for sketches, lengths, labels in train_set.take(1):\n",
    "    draw_sketches(sketches, lengths, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = np.concatenate([lengths for _, lengths, _ in train_set.take(1000)])\n",
    "\n",
    "def crop_long_sketches(dataset, max_length=100):\n",
    "    return dataset.map(lambda inks, lengths, labels: (inks[:, :max_length], labels))\n",
    "\n",
    "cropped_train_set = crop_long_sketches(train_set)\n",
    "cropped_valid_set = crop_long_sketches(valid_set)\n",
    "cropped_test_set = crop_long_sketches(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(32, kernel_size=5, strides=2, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv1D(64, kernel_size=5, strides=2, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv1D(128, kernel_size=3, strides=2, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.LSTM(128, return_sequences=True),\n",
    "    keras.layers.LSTM(128),\n",
    "    keras.layers.Dense(len(class_names), activation=\"softmax\")\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-2, clipnorm=1.)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\", \"sparse_top_k_categorical_accuracy\"])\n",
    "history = model.fit(cropped_train_set, epochs=5, validation_data=cropped_valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.concatenate([labels for _, _, labels in test_set])\n",
    "y_probas = model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(keras.metrics.sparse_top_k_categorical_accuracy(y_test, y_probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_new = 10\n",
    "Y_probas = model.predict(sketches)\n",
    "top_k = tf.nn.top_k(Y_probas, k=5)\n",
    "for index in range(n_new):\n",
    "    plt.figure(figsize=(3, 3.5))\n",
    "    draw_sketch(sketches[index])\n",
    "    plt.show()\n",
    "    print(\"Top-5 predictions:\".format(index + 1))\n",
    "    for k in range(5):\n",
    "        class_name = class_names[top_k.indices[index, k]]\n",
    "        proba = 100 * top_k.values[index, k]\n",
    "        print(\"  {}. {} {:.3f}%\".format(k + 1, class_name, proba))\n",
    "    print(\"Answer: {}\".format(class_names[labels[index].numpy()]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4e1c02ba9a4315c9c9b9f3ccdc568bf0028a114bbf7c4447cf8df78c88a2f71"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('handson-ml2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
